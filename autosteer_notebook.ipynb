{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1b8d37c",
   "metadata": {},
   "source": [
    "# AutoSteer Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b255d82",
   "metadata": {},
   "source": [
    "## detect middle line on a road inside FS22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82198dfe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-21T15:40:37.273957Z",
     "start_time": "2022-10-21T15:40:37.261959Z"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline\n",
    "import sklearn\n",
    "import glob\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "674bbb73-e37c-4179-835a-e01e53773835",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Canny and HSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99dd7469",
   "metadata": {},
   "outputs": [],
   "source": [
    "def roi(img_mask,img, vertices):\n",
    "    mask = np.zeros_like(img_mask)\n",
    "    cv2.fillPoly(mask,vertices,255)\n",
    "    masked = cv2.bitwise_and(img, mask)\n",
    "    return masked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc2e826",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-21T16:22:11.622729Z",
     "start_time": "2022-10-21T16:22:10.436944Z"
    }
   },
   "outputs": [],
   "source": [
    "def readImg(path):\n",
    "    \n",
    "    #img = cv2.imread(\"./images/img2.png\")\n",
    "    img = cv2.imread(path)\n",
    "    size = (1280, 720)\n",
    "    img = cv2.resize(img, size)\n",
    "    org_img = np.copy(img)\n",
    "    return org_img\n",
    "\n",
    "def hsv(hsv_img):\n",
    "    hsv = cv2.cvtColor(hsv_img, cv2.COLOR_BGR2HSV)\n",
    "    sensitivity = 70\n",
    "    lower_white = np.array([0,0,255-sensitivity])\n",
    "    upper_white = np.array([255,sensitivity,255])\n",
    "    mask = cv2.inRange(hsv, lower_white, upper_white)\n",
    "    res = cv2.bitwise_and(hsv_img,hsv_img, mask= mask)\n",
    "    #hsv_img = res\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8915a6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-21T16:24:02.545474Z",
     "start_time": "2022-10-21T16:24:00.557980Z"
    }
   },
   "outputs": [],
   "source": [
    "def canny_and_roi(img,in_roi,togray=True):\n",
    "    if togray:\n",
    "        img_gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    else:\n",
    "        img_gray = np.copy(img)\n",
    "    kernel_size = 5\n",
    "    blur_gray = cv2.GaussianBlur(img_gray,(kernel_size, kernel_size),0)\n",
    "    #cv2.imshow('image',blur_gray)\n",
    "    #cv2.waitKey()\n",
    "    #cv2.destroyAllWindows()\n",
    "    low_threshold = 120\n",
    "    high_threshold = 265\n",
    "    edges = cv2.Canny(blur_gray, low_threshold, high_threshold)\n",
    "    if in_roi:\n",
    "    #roi_vertices = vertices = np.array([[0,500],[10,300], [300,200], [500,200], [800,300], [800,500]], np.int32)\n",
    "        roi_vertices = np.array([[340,700],[340,300], [250,80], [530,80], [880,300], [880,700]], np.int32)\n",
    "        processed_img = roi(edges, [roi_vertices])\n",
    "        return processed_img\n",
    "    else:\n",
    "        return edges\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8a74e8",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-10-21T16:25:26.100Z"
    }
   },
   "outputs": [],
   "source": [
    "def hough(h_img,org_img):\n",
    "    rho = 1  # distance resolution in pixels of the Hough grid\n",
    "    theta = np.pi / 180  # angular resolution in radians of the Hough grid\n",
    "    threshold = 50  # minimum number of votes (intersections in Hough grid cell)\n",
    "    min_line_length = 40  # minimum number of pixels making up a line\n",
    "    max_line_gap = 35  # maximum gap in pixels between connectable line segments\n",
    "    line_image = np.copy(org_img) # * 0  # creating a blank to draw lines on\n",
    "    size = (1280, 720)\n",
    "    # Run Hough on edge detected image\n",
    "    # Output \"lines\" is an array containing endpoints of detected line segments\n",
    "    lines = cv2.HoughLinesP(h_img, rho, theta, threshold, np.array([]),\n",
    "                        min_line_length, max_line_gap)\n",
    "    line_m = []\n",
    "    y_max = 800\n",
    "    for line in lines:\n",
    "        for x1,y1,x2,y2 in line:\n",
    "            cv2.line(line_image,(x1,y1),(x2,y2),(255,255,0),2)\n",
    "            m = (y2-y1)/(x2-x1)\n",
    "            if x2<size[0]/2:\n",
    "                if m < -6 :\n",
    "                    line_m += [m]\n",
    "\n",
    "                #get \n",
    "                if y1 < y_max:\n",
    "                    y_max = y1\n",
    "                    line_max = (x1,y1)\n",
    "                if y2 < y_max:\n",
    "                    y_max = y2\n",
    "                    line_max = (x2,y2)\n",
    "\n",
    "    print(\"point with maximum y value (near bottom of screen): \",line_max)        \n",
    "    print(\"all m of lines: \",line_m)\n",
    "    mean_m = np.mean(line_m)\n",
    "    print(\"avergae m of lines: \",mean_m)\n",
    "\n",
    "    #Geradengleichung y = mx + n\n",
    "    #n = y-m*x\n",
    "    n = line_max[1] - mean_m * line_max[0]\n",
    "    print(\"average line n: \",n)\n",
    "\n",
    "\n",
    "    #draw line with average m from bottom point of all lines to edge of screen point\n",
    "    edge_screen_y = 700\n",
    "    edge_screen_x = (edge_screen_y - n)/mean_m\n",
    "    edge_point = (int(edge_screen_x),int(edge_screen_y))\n",
    "\n",
    "    cv2.circle(line_image,line_max,5,(255,0,255),5)   \n",
    "    cv2.circle(line_image,edge_point,5,(255,0,255),5)  \n",
    "    cv2.line(line_image,line_max,edge_point,(255,0,255),2)\n",
    "\n",
    "    #draw image center\n",
    "    cv2.circle(line_image,(int(size[0]/2),int(size[1]/2)),5,(255,255,255),5)        \n",
    "\n",
    "\n",
    "    #draw middle line at center\n",
    "    middle_screen_y = size[1]/2\n",
    "    middle_screen_x = (middle_screen_y - n)/mean_m\n",
    "    middle_point = (int(middle_screen_x),int(middle_screen_y))\n",
    "    cv2.circle(line_image,middle_point,5,(255,0,255),5)  \n",
    "\n",
    "    #calc distance between line and center at center height\n",
    "    print(\"diff line: \",size[0]/2 - middle_screen_x)\n",
    "\n",
    "\n",
    "\n",
    "    return line_image, size[0]/2 - middle_screen_x\n",
    "    #cv2.imshow('image',line_image)\n",
    "    #cv2.waitKey(0)\n",
    "    #cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b81862c",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = readImg(\"./images/img5.png\")\n",
    "img1 = hsv(img)\n",
    "processed_img = canny_and_roi(img1)\n",
    "processed_img1,diff = hough(processed_img,img)\n",
    "plt.figure(figsize=(6, 4), dpi=150)\n",
    "plt_img = cv2.cvtColor(processed_img1,cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(plt_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6efe0749",
   "metadata": {},
   "source": [
    "Problem with other lines detected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd9a9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "diffs = []\n",
    "for file in glob.glob(\"./sequence/1/*.png\"):\n",
    "    print(file)\n",
    "    img = readImg(file)\n",
    "    img1 = hsv(img)\n",
    "    processed_img = canny_and_roi(img1)\n",
    "    processed_img1,diff = hough(processed_img,img)\n",
    "    diffs += [diff]\n",
    "    cv2.imshow('image',processed_img1)\n",
    "    cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n",
    "print(diffs)\n",
    "#compare current distance between middle point and line middle and the distance in the frame before\n",
    "#steer accordingly\n",
    "#at the beginning: set an optimal distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4155d67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 4), dpi=150)\n",
    "plt_img = cv2.cvtColor(line_image,cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(plt_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ecabd41",
   "metadata": {},
   "source": [
    "## Detect outer edge of Car/Tractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "462a8c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"./images/img1.png\")\n",
    "size = (1280, 720)\n",
    "img = cv2.resize(img, size)\n",
    "org_img = np.copy(img)\n",
    "cv2.imshow('image',org_img)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455c6719",
   "metadata": {},
   "outputs": [],
   "source": [
    "#size = (1280, 720)\n",
    "roi_box_size = 150\n",
    "center = tuple(int(s/2) for s in size)\n",
    "print(center)\n",
    "roi_vertices_box = np.array([[center[0]-roi_box_size,center[1]-roi_box_size],\n",
    "                         [center[0]-roi_box_size,center[1]+roi_box_size],\n",
    "                         [center[0]+roi_box_size,center[1]+roi_box_size],\n",
    "                         [center[0]+roi_box_size,center[1]-roi_box_size]], np.int32)\n",
    "#img = cv2.cvtColor(org_img,cv2.COLOR_BGR2GRAY)\n",
    "processed_img = roi(img, [roi_vertices_box])\n",
    "\n",
    "cv2.imshow('image',processed_img)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14349561",
   "metadata": {},
   "outputs": [],
   "source": [
    "low_threshold = 130\n",
    "high_threshold = 200\n",
    "def on_low(val):\n",
    "    global low_threshold\n",
    "    low_threshold = val\n",
    "    cv2.setTrackbarPos(\"low\", 'Canny Edge Detection', low_threshold)\n",
    "def on_high(val):\n",
    "    global high_threshold\n",
    "    high_threshold = val\n",
    "    cv2.setTrackbarPos(\"high\", 'Canny Edge Detection', high_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397163d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.namedWindow('Canny Edge Detection')\n",
    "cv2.createTrackbar(\"low\",'Canny Edge Detection',0,255,on_low)\n",
    "cv2.createTrackbar(\"high\",'Canny Edge Detection',0,255,on_high)\n",
    "low_threshold = 130\n",
    "high_threshold = 200\n",
    "while(1):\n",
    "    edges = cv2.Canny(processed_img, low_threshold, high_threshold)\n",
    "    cv2.imshow('Canny Edge Detection',edges)\n",
    "    k = cv2.waitKey(1) & 0xFF\n",
    "    if k == 27:\n",
    "        break\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5761623e",
   "metadata": {},
   "outputs": [],
   "source": [
    "low_threshold = 105\n",
    "high_threshold = 255\n",
    "edges = cv2.Canny(processed_img, low_threshold, high_threshold)\n",
    "cv2.imshow('Canny Edge Detection',edges)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "573d3eee",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# TEST\n",
    "\n",
    "https://stackoverflow.com/questions/45531074/how-to-merge-lines-after-houghlinesp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3f950f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HoughBundler:     \n",
    "    def __init__(self,min_distance=5,min_angle=2):\n",
    "        self.min_distance = min_distance\n",
    "        self.min_angle = min_angle\n",
    "    \n",
    "    def get_orientation(self, line):\n",
    "        orientation = math.atan2(abs((line[3] - line[1])), abs((line[2] - line[0])))\n",
    "        return math.degrees(orientation)\n",
    "\n",
    "    def check_is_line_different(self, line_1, groups, min_distance_to_merge, min_angle_to_merge):\n",
    "        for group in groups:\n",
    "            for line_2 in group:\n",
    "                if self.get_distance(line_2, line_1) < min_distance_to_merge:\n",
    "                    orientation_1 = self.get_orientation(line_1)\n",
    "                    orientation_2 = self.get_orientation(line_2)\n",
    "                    if abs(orientation_1 - orientation_2) < min_angle_to_merge:\n",
    "                        group.append(line_1)\n",
    "                        return False\n",
    "        return True\n",
    "\n",
    "    def distance_point_to_line(self, point, line):\n",
    "        px, py = point\n",
    "        x1, y1, x2, y2 = line\n",
    "\n",
    "        def line_magnitude(x1, y1, x2, y2):\n",
    "            line_magnitude = math.sqrt(math.pow((x2 - x1), 2) + math.pow((y2 - y1), 2))\n",
    "            return line_magnitude\n",
    "\n",
    "        lmag = line_magnitude(x1, y1, x2, y2)\n",
    "        if lmag < 0.00000001:\n",
    "            distance_point_to_line = 9999\n",
    "            return distance_point_to_line\n",
    "\n",
    "        u1 = (((px - x1) * (x2 - x1)) + ((py - y1) * (y2 - y1)))\n",
    "        u = u1 / (lmag * lmag)\n",
    "\n",
    "        if (u < 0.00001) or (u > 1):\n",
    "            #// closest point does not fall within the line segment, take the shorter distance\n",
    "            #// to an endpoint\n",
    "            ix = line_magnitude(px, py, x1, y1)\n",
    "            iy = line_magnitude(px, py, x2, y2)\n",
    "            if ix > iy:\n",
    "                distance_point_to_line = iy\n",
    "            else:\n",
    "                distance_point_to_line = ix\n",
    "        else:\n",
    "            # Intersecting point is on the line, use the formula\n",
    "            ix = x1 + u * (x2 - x1)\n",
    "            iy = y1 + u * (y2 - y1)\n",
    "            distance_point_to_line = line_magnitude(px, py, ix, iy)\n",
    "\n",
    "        return distance_point_to_line\n",
    "\n",
    "    def get_distance(self, a_line, b_line):\n",
    "        dist1 = self.distance_point_to_line(a_line[:2], b_line)\n",
    "        dist2 = self.distance_point_to_line(a_line[2:], b_line)\n",
    "        dist3 = self.distance_point_to_line(b_line[:2], a_line)\n",
    "        dist4 = self.distance_point_to_line(b_line[2:], a_line)\n",
    "\n",
    "        return min(dist1, dist2, dist3, dist4)\n",
    "\n",
    "    def merge_lines_into_groups(self, lines):\n",
    "        groups = []  # all lines groups are here\n",
    "        # first line will create new group every time\n",
    "        groups.append([lines[0]])\n",
    "        # if line is different from existing gropus, create a new group\n",
    "        for line_new in lines[1:]:\n",
    "            if self.check_is_line_different(line_new, groups, self.min_distance, self.min_angle):\n",
    "                groups.append([line_new])\n",
    "\n",
    "        return groups\n",
    "\n",
    "    def merge_line_segments(self, lines):\n",
    "        orientation = self.get_orientation(lines[0])\n",
    "      \n",
    "        if(len(lines) == 1):\n",
    "            return np.block([[lines[0][:2], lines[0][2:]]])\n",
    "\n",
    "        points = []\n",
    "        for line in lines:\n",
    "            points.append(line[:2])\n",
    "            points.append(line[2:])\n",
    "        if 45 < orientation <= 90:\n",
    "            #sort by y\n",
    "            points = sorted(points, key=lambda point: point[1])\n",
    "        else:\n",
    "            #sort by x\n",
    "            points = sorted(points, key=lambda point: point[0])\n",
    "\n",
    "        return np.block([[points[0],points[-1]]])\n",
    "\n",
    "    def process_lines(self, lines):\n",
    "        lines_horizontal  = []\n",
    "        lines_vertical  = []\n",
    "  \n",
    "        for line_i in [l[0] for l in lines]:\n",
    "            orientation = self.get_orientation(line_i)\n",
    "            # if vertical\n",
    "            if 45 < orientation <= 90:\n",
    "                lines_vertical.append(line_i)\n",
    "            else:\n",
    "                lines_horizontal.append(line_i)\n",
    "\n",
    "        lines_vertical  = sorted(lines_vertical , key=lambda line: line[1])\n",
    "        lines_horizontal  = sorted(lines_horizontal , key=lambda line: line[0])\n",
    "        merged_lines_all = []\n",
    "\n",
    "        # for each cluster in vertical and horizantal lines leave only one line\n",
    "        for i in [lines_horizontal, lines_vertical]:\n",
    "            if len(i) > 0:\n",
    "                groups = self.merge_lines_into_groups(i)\n",
    "                merged_lines = []\n",
    "                for group in groups:\n",
    "                    merged_lines.append(self.merge_line_segments(group))\n",
    "                merged_lines_all.extend(merged_lines)\n",
    "                    \n",
    "        return np.asarray(merged_lines_all)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc37d7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usage:\n",
    "img = readImg(\"images/img3.png\")\n",
    "edges = canny_and_roi(img,True)\n",
    "#lines = cv2.HoughLinesP(edges, 1, np.pi / 180, 50, None, 50, 10)\n",
    "\n",
    "\n",
    "rho = 1  # distance resolution in pixels of the Hough grid\n",
    "theta = np.pi / 180  # angular resolution in radians of the Hough grid\n",
    "threshold = 70  # minimum number of votes (intersections in Hough grid cell)\n",
    "min_line_length = 45  # minimum number of pixels making up a line\n",
    "max_line_gap = 75  # maximum gap in pixels between connectable line segments\n",
    "#line_image = np.copy(org_img) # * 0  # creating a blank to draw lines on\n",
    "size = (1280, 720)\n",
    "# Run Hough on edge detected image\n",
    "# Output \"lines\" is an array containing endpoints of detected line segments\n",
    "lines_normal = cv2.HoughLinesP(edges, rho, theta, threshold, np.array([]),\n",
    "                    min_line_length, max_line_gap)\n",
    "bundler = HoughBundler(min_distance=5,min_angle=0)\n",
    "lines = bundler.process_lines(lines_normal)\n",
    "print(lines)\n",
    "line_image = np.copy(img)\n",
    "for line in lines:\n",
    "    for x1,y1,x2,y2 in line:\n",
    "        cv2.line(line_image,(x1,y1),(x2,y2),(255,255,0),4)\n",
    "\n",
    "for line in lines_normal:\n",
    "    for x1,y1,x2,y2 in line:\n",
    "        cv2.line(line_image,(x1,y1),(x2,y2),(0,0,0),1)\n",
    "cv2.imshow('image',line_image)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa4b8e86",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1bcd072-b9f4-4644-933a-56efeb568490",
   "metadata": {},
   "source": [
    "# Filtering and FindContours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2285dcf-107a-4ca3-80e1-f6e7e34cb3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_images(images, titles=None):\n",
    "    fig, ax = plt.subplots(ncols=len(images), figsize=(len(images)*5,5))\n",
    "\n",
    "    for idx, image in enumerate(images):\n",
    "        ax[idx].imshow(image, cmap='gray')\n",
    "        ax[idx].axis(False)\n",
    "        if(titles != None):\n",
    "            ax[idx].set_title(titles[idx])\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e719824a-921c-460c-b6d9-a09f04afd97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.filters import try_all_threshold, threshold_yen\n",
    "from skimage import color,io,exposure\n",
    "\n",
    "from skimage.morphology import erosion, dilation, opening, closing, diamond\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188dc471",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.filters import try_all_threshold, threshold_yen\n",
    "from skimage import color,io,exposure\n",
    "\n",
    "from skimage.morphology import erosion, dilation, opening, closing, diamond\n",
    "\n",
    "\n",
    "# read image\n",
    "org_img = io.imread('./images/img7.jpg')\n",
    "image = np.copy(org_img)\n",
    "image = color.rgb2gray(image)\n",
    "img_hist = exposure.equalize_hist(image)\n",
    "\n",
    "# Apply all methods and visualize results\n",
    "#try_all_threshold(image, figsize=(10,8), verbose=False)\n",
    "thresh = threshold_yen(image, nbins=128)\n",
    "print(thresh)\n",
    "\n",
    "# computer binary image\n",
    "image_bin = image > thresh\n",
    "#image_bin = image <= thresh\n",
    "\n",
    "\n",
    "plt.imshow(image_bin, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec02a137-d853-4ef8-a545-665dd3d1370e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#element = np.array([[0, 1, 0], \n",
    "#                    [1, 1, 1], \n",
    "#                    [0, 1, 0]])\n",
    "elements = [np.ones((1,2), dtype=int),\n",
    "    #np.array([[1, 1, 1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1]]),\n",
    "            np.array([[0, 1, 0], \n",
    "                      [1, 1, 1], \n",
    "                      [0, 1, 0]])\n",
    "            #np.array([[1,0],[0,1]]),\n",
    "            #np.array([[0,1],[1,0]])\n",
    "           #np.array([[1, 1, 1], \n",
    "           #           [1, 1, 1]]),\n",
    "           \n",
    "           ]\n",
    "for element in elements:\n",
    "    print(element)\n",
    "    image_bin = erosion(image_bin, footprint=element)\n",
    "print(np.max(image_bin))\n",
    "print(image_bin.dtype)\n",
    "plt.imshow(image_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f08ea8-3945-4682-992f-a723d823cc16",
   "metadata": {},
   "outputs": [],
   "source": [
    "#image_bin = dilation(image_bin, footprint=np.ones((1,100), dtype=int))\n",
    "#plt.imshow(image_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5edda3e0-9a10-45dd-b142-3d92f415d033",
   "metadata": {},
   "outputs": [],
   "source": [
    "#roi_vertices = vertices = np.array([[0,500],[10,300], [300,200], [500,200], [800,300], [800,500]], np.int32)\n",
    "#roi_vertices = np.array([[340,700],[340,300], [250,80], [530,80], [880,300], [880,700]], np.int32)\n",
    "#cv2.fillPoly(image,roi_vertices,255)\n",
    "#processed_img = roi(image,image_bin, [roi_vertices])\n",
    "image = exposure.rescale_intensity(image_bin,in_range=(0,1),out_range='uint8')\n",
    "contours = cv2.findContours(image, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "#show_images([image_bin,processed_img])\n",
    "#print(contours)\n",
    "#print(contours[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6241053f-6a17-49d2-b3f5-2a63dcd64efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cv2.drawContours(org_img, contours, -1, (0, 255, 0), 3)\n",
    "image = cv2.drawContours(org_img, contours[0], -1, (0,255,0), 3)\n",
    "#plt.imshow(image, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9855af1-eaaa-4f18-bc8c-229af19dffb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def not_in__middle(x,y,dist,image):\n",
    "    x_mid = image.shape[1]//2\n",
    "    y_mid = image.shape[0]//2\n",
    "    \n",
    "    #return true if pixel is out of middle area\n",
    "    #return (x < x_mid - dist or x > x_mid + dist) and (y < y_mid - dist or y > y_mid + dist)\n",
    "    return (x < x_mid - dist or x > x_mid + dist) and (y < y_mid - y_mid or y > y_mid + dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb4827e-b817-4762-bb0c-1c6fabb15793",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(contours[0])\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from scipy import stats\n",
    "x_arr = []\n",
    "y_arr = []\n",
    "for c in contours[0]:\n",
    "    #print(len(c))\n",
    "    if len(c) > 12:\n",
    "        #print(c)\n",
    "        #print(c[0][0][0],c[0][0][1])\n",
    "        (x,y) = (c[0][0][0],c[0][0][1])\n",
    "        if x > 500 and x < 1500 and not_in__middle(x,y,100,image):\n",
    "            cv2.circle(image, (x,y),10,(0,0,0))\n",
    "        \n",
    "            for element in c:\n",
    "                #print(element)\n",
    "                x_arr.append([x])\n",
    "                y_arr.append([y])\n",
    "                #np.append(x_arr, [x], axis=0)\n",
    "                #np.append(y_arr, [y], axis=0)\n",
    "                \n",
    "x_arr = np.array([x_arr]).reshape((-1, 1))#.ravel()\n",
    "y_arr = np.array([y_arr]).reshape((1,-1)).ravel()\n",
    "#print(x_arr)\n",
    "#print(y_arr)\n",
    "#x_arr.reshape((-1, 1))\n",
    "print(x_arr.shape)\n",
    "print(y_arr.shape)\n",
    "#y_arr\n",
    "\n",
    "#linear regression with sklearn\n",
    "model = LinearRegression()\n",
    "pred = model.fit(x_arr,y_arr)\n",
    "print(pred)\n",
    "#for x in range(750,1000):\n",
    "x_1d = np.arange(750,1000)\n",
    "x = x_1d.reshape((-1, 1))\n",
    "print(x.shape)\n",
    "y_pred = model.predict(x)\n",
    "\n",
    "\n",
    "\n",
    "#linear regression with numpy\n",
    "x_np = x_arr.reshape((1, -11))[0]\n",
    "(m, b) = np.polyfit(x_np, y_arr, 1)\n",
    "print(m,b)\n",
    "yp = np.polyval([m, b], x_1d)\n",
    "print(yp)\n",
    "\n",
    "\n",
    "#y_pred = model.coef_[0]*x + model.coef_[1]*xfit**2 + model.intercept_\n",
    "#y_pred = model.coef_[0]*x + model.intercept_\n",
    "#print(x,y_pred)\n",
    "for idx,x_element in enumerate(x):\n",
    "    if idx < 10:\n",
    "        print(x[idx],y_pred[idx])\n",
    "    #sklearn regression\n",
    "    cv2.circle(image, (int(x[idx]),int(y_pred[idx])),10,(255,0,0))\n",
    "    #numpy regression\n",
    "    cv2.circle(image, (int(x[idx]),int(yp[idx])),10,(0,255,0))\n",
    "x1 = x[0][0]\n",
    "y1 = int(y_pred[0])\n",
    "x2 = x[-1][0]\n",
    "y2 = int(y_pred[-1])\n",
    "cv2.line(image,(x1,y1),(x2,y2),(255,255,0),2)\n",
    "\n",
    "\n",
    "#draw middle line at center\n",
    "print(\"image shape: \", image.shape)\n",
    "middle_screen_y = image.shape[0]//2\n",
    "print(\"middle_screen_y: \",middle_screen_y)\n",
    "middle_screen_x = (middle_screen_y - model.intercept_)/model.coef_[0]\n",
    "middle_point = (int(middle_screen_x),int(middle_screen_y))\n",
    "cv2.circle(image,middle_point,5,(255,255,255),5)  \n",
    "cv2.circle(image,(image.shape[1]//2,image.shape[0]//2),5,(255,255,255),5)  \n",
    "#calc distance between line and center at center height\n",
    "diff_line = image.shape[1]//2 - middle_screen_x\n",
    "print(\"diff line: \",diff_line)\n",
    "\n",
    "\n",
    "plt.imshow(image, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77cdcd1f-f405-4401-97ab-e91f69930b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"window\",image)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d258e7-5bdb-4751-b503-6383d7ca7e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(org_img))\n",
    "print(\"img1.jpg\")\n",
    "m, b, r_value, p_value, std_err = stats.linregress(x_np, y_arr)\n",
    "print(m)\n",
    "print(b)\n",
    "print(r_value)\n",
    "print(p_value)\n",
    "print(std_err) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22895ce0-f594-44da-9349-1c5b7e3679a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(org_img))\n",
    "print(\"img5.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a73976-2eff-4d78-9259-e4c997782583",
   "metadata": {},
   "outputs": [],
   "source": [
    "m, b, r_value, p_value, std_err = stats.linregress(x_np, y_arr)\n",
    "print(m)\n",
    "print(b)\n",
    "print(r_value)\n",
    "print(p_value)\n",
    "print(std_err) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec395a84-eaf8-463d-848e-e0c77c96f92b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_difference_line(img,show=False,nbins=128):\n",
    "    def not_in__middle(x,y,dist,image):\n",
    "        x_mid = image.shape[1]//2\n",
    "        y_mid = image.shape[0]//2\n",
    "\n",
    "        #return true if pixel is in desired area out of middle area\n",
    "        #true if pixel should be used for regression\n",
    "        #pixel is in area:\n",
    "        middle_x = (x < x_mid - dist or x > x_mid + dist)\n",
    "        middle_y = (y < y_mid - y_mid or y > y_mid + dist)\n",
    "        left_and_right_edge = (x > 300 and x < 1200)\n",
    "        \n",
    "        #return (x < x_mid - dist or x > x_mid + dist) and (y < y_mid - dist or y > y_mid + dist)\n",
    "        return middle_x and middle_y and left_and_right_edge\n",
    "    org_img = img\n",
    "    image = np.copy(img)\n",
    "    image = color.rgb2gray(image)\n",
    "    thresh = threshold_yen(image, nbins=nbins)\n",
    "    if show:\n",
    "        print(thresh)\n",
    "    image_bin = image > thresh\n",
    "    elements = [np.ones((1,2), dtype=int),np.array([[0, 1, 0], [1, 1, 1], [0, 1, 0]])]\n",
    "    for element in elements:\n",
    "        if show:\n",
    "            print(element)\n",
    "        image_bin = erosion(image_bin, footprint=element)\n",
    "    if show:\n",
    "        print(\"Maximalwert des Binärbildes: \",np.max(image_bin))\n",
    "        print(\"Datentyp des Binärbildes: \",image_bin.dtype)\n",
    "    image = exposure.rescale_intensity(image_bin,in_range=(0,1),out_range='uint8')\n",
    "    contours = cv2.findContours(image, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    if show:\n",
    "        image = cv2.drawContours(org_img, contours[0], -1, (0,255,0), 3)\n",
    "    x_arr = []\n",
    "    y_arr = []\n",
    "    if len(contours[0]):\n",
    "        for c in contours[0]:\n",
    "            if len(c) > 12:\n",
    "                (x,y) = (c[0][0][0],c[0][0][1])\n",
    "                if x > 500 and x < 1500 and not_in__middle(x,y,100,image):\n",
    "                    cv2.circle(image, (x,y),10,(0,0,0))\n",
    "                    for element in c:\n",
    "                        x_arr.append([x])\n",
    "                        y_arr.append([y])\n",
    "                \n",
    "        x_arr = np.array([x_arr]).reshape((-1, 1))#.ravel()\n",
    "        y_arr = np.array([y_arr]).reshape((1,-1)).ravel()\n",
    "        if show:\n",
    "            print(\"Konturpunkte x Shape: \",x_arr.shape)\n",
    "            print(\"Konturpunkte y Shape: \",y_arr.shape)\n",
    "\n",
    "        #linear regression with sklearn\n",
    "        model = LinearRegression()\n",
    "        pred = model.fit(x_arr,y_arr)\n",
    "        x_1d = np.arange(750,1000) #hier muss theoertisch nur in der Mitte des Bildes die Xwerte angeschaut werden\n",
    "        x = x_1d.reshape((-1, 1))\n",
    "        if show:\n",
    "            print(\"X Werte neu Shape: \",x.shape)\n",
    "        y_pred = model.predict(x)\n",
    "\n",
    "\n",
    "\n",
    "        #linear regression with numpy\n",
    "        x_np = x_arr.reshape((1, -11))[0]\n",
    "        (m, b) = np.polyfit(x_np, y_arr, 1)\n",
    "        #print(m,b)\n",
    "        yp = np.polyval([m, b], x_1d)\n",
    "        #print(yp)\n",
    "\n",
    "\n",
    "        #y_pred = model.coef_[0]*x + model.coef_[1]*xfit**2 + model.intercept_\n",
    "        #y_pred = model.coef_[0]*x + model.intercept_\n",
    "        for idx,x_element in enumerate(x):\n",
    "            if show:\n",
    "                if idx < 10 and show:\n",
    "                    print(x[idx],y_pred[idx])\n",
    "                #sklearn regression\n",
    "                cv2.circle(image, (int(x[idx]),int(y_pred[idx])),10,(255,0,0))\n",
    "                #numpy regression\n",
    "                cv2.circle(image, (int(x[idx]),int(yp[idx])),10,(0,255,0))\n",
    "        if show:\n",
    "            x1 = x[0][0]\n",
    "            y1 = int(y_pred[0])\n",
    "            x2 = x[-1][0]\n",
    "            y2 = int(y_pred[-1])\n",
    "            cv2.line(image,(x1,y1),(x2,y2),(255,255,0),2)\n",
    "\n",
    "\n",
    "        #draw middle line at center\n",
    "        \n",
    "        middle_screen_y = image.shape[0]//2\n",
    "        middle_screen_x = (middle_screen_y - model.intercept_)/model.coef_[0]\n",
    "        middle_point = (int(middle_screen_x),int(middle_screen_y))\n",
    "        diff_line = image.shape[1]//2 - middle_screen_x\n",
    "\n",
    "        if show:\n",
    "            print(\"image shape: \", image.shape)\n",
    "            print(\"middle_screen_y: \",middle_screen_y)\n",
    "            print(\"middle_screen_x: \",middle_screen_x)\n",
    "            cv2.circle(image,middle_point,5,(255,255,255),5)  \n",
    "            cv2.circle(image,(image.shape[1]//2,image.shape[0]//2),5,(255,255,255),5)  \n",
    "            #calc distance between line and center at center height\n",
    "            print(\"diff line: \",diff_line)\n",
    "        if not show:\n",
    "            image = None\n",
    "    return diff_line,image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "357cee51-993a-411d-9bb5-10838d6f1fd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122.76491228070176\n"
     ]
    }
   ],
   "source": [
    "#img = io.imread('./images/img5.jpg')\n",
    "from autosteerfunctions import calculate_difference_line\n",
    "import cv2\n",
    "img = cv2.imread('./images/img5.jpg')\n",
    "diff_line,image = calculate_difference_line(img,False)\n",
    "if image is not None:\n",
    "    plt.imshow(image)\n",
    "print(diff_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81225c52-e40b-426b-982b-07e95f4efb0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d7a96f00-b3d8-4f1c-8e1b-62320e181544",
   "metadata": {},
   "source": [
    "# PID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9999a80-49bd-4c85-90ec-b01e8f0bd51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install simple-pid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6da734a-d542-49ba-92f0-b90e20785c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "from simple_pid import PID\n",
    "pid = PID(4, 0.1, 0.05, setpoint=120)\n",
    "\n",
    "# Assume we have a system we want to control in controlled_system\n",
    "#v = controlled_system.update(0)\n",
    "diff_line = 125\n",
    "x_pid = np.arange(0,100)\n",
    "y_pid = []\n",
    "for x in range(100):\n",
    "    # Compute new output from the PID according to the systems current value\n",
    "    control = pid(diff_line)\n",
    "    print(control)\n",
    "    # Feed the PID output to the system and get its current value\n",
    "    #v = controlled_system.update(control)\n",
    "    diff_line = diff_line - control\n",
    "    y_pid.append(diff_line)\n",
    "print(y_pid)\n",
    "plt.plot(x_pid,y_pid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76eaa18e-3d9b-4120-bd2e-df3caaedfff5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dc251545-48e1-4e5e-ae27-7c8e1c60f763",
   "metadata": {},
   "source": [
    "# All together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f91fbc9a-e8b3-406c-a4e5-8ed577bde28d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Name: py_joy.py\n",
      "Size: 2.9 KB\n",
      "Path: autosteer\n",
      "Created: 2023-01-09 18:37:42\n",
      "Modified: 2023-01-09 19:10:10\n",
      "Writable: true\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Akkustand\n",
      "\n",
      "Network Flyout\n",
      "\n",
      "jupyterlab/jupyterlab-git: A Git extension for JupyterLab\n",
      "\n",
      "Window\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "autosteer_no… (auto-8 : 2) - JupyterLab – Mozilla Firefox\n",
      "\n",
      "\n",
      "\n",
      "Screenshot-Uploader\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Server\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Steam\n",
      "\n",
      "\n",
      "\n",
      "Freunde\n",
      "\n",
      "\n",
      "\n",
      "Windows PowerShell\n",
      "PyCharm\n",
      "theAwtToolkitWindow\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "autosteer\n",
      "\n",
      "\n",
      "\n",
      "C:\\projects\\autosteer\\autosteerfunctions.py - Notepad++\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Status\n",
      "GDI+ Window (Explorer.EXE)\n",
      "Windows PowerShell\n",
      "Groove-Musik\n",
      "Groove-Musik\n",
      "\n",
      "Einstellungen\n",
      "Einstellungen\n",
      "Microsoft Text Input Application\n",
      "\n",
      "\n",
      "\n",
      "WinEventHub\n",
      "Microsoft OneNote – Windows-Taskleiste\n",
      "GDI+ Window (ONENOTEM.EXE)\n",
      "Window\n",
      "\n",
      "FreeMeter 2.30.0\n",
      "GDI+ Window (OneDrive.exe)\n",
      "NotifyIconWindowTitle\n",
      "\n",
      "SecurityHealthSystray\n",
      "DDE Server Window\n",
      "\n",
      "\n",
      "\n",
      "OneDrive - Persönlich\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "BluetoothNotificationAreaIconWindowClass\n",
      "MS_WebcheckMonitor\n",
      "\n",
      "\n",
      "DDE Server Window\n",
      "NvSvc\n",
      "UxdService\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Windows Push Notifications Platform\n",
      "Task Host Window\n",
      "NVIDIA WMI Provider\n",
      "NvContainerWindowClass00000B50\n",
      "DWM Notification Window\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Farming Simulator 22\n",
      "found game\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Maurice\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\skimage\\filters\\thresholding.py:440: RuntimeWarning: divide by zero encountered in reciprocal\n",
      "  crit = np.log(((P1_sq[:-1] * P2_sq[1:]) ** -1) *\n",
      "C:\\Users\\Maurice\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\skimage\\filters\\thresholding.py:440: RuntimeWarning: invalid value encountered in multiply\n",
      "  crit = np.log(((P1_sq[:-1] * P2_sq[1:]) ** -1) *\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found array with 0 sample(s) (shape=(0, 1)) while a minimum of 1 is required by LinearRegression.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [6], line 35\u001b[0m\n\u001b[0;32m     33\u001b[0m     screenshot \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(screenshot)\n\u001b[0;32m     34\u001b[0m     screenshot \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(screenshot, cv2\u001b[38;5;241m.\u001b[39mCOLOR_RGB2BGR)\n\u001b[1;32m---> 35\u001b[0m     diff_line,image \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_difference_line\u001b[49m\u001b[43m(\u001b[49m\u001b[43mscreenshot\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     36\u001b[0m     \u001b[38;5;28mprint\u001b[39m(diff_line)\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m#diff_line,image = calculate_difference_line(img,False)\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m#if image is not None:\u001b[39;00m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m#    plt.imshow(image)\u001b[39;00m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;66;03m#print(diff_line)\u001b[39;00m\n",
      "File \u001b[1;32mC:\\projects\\autosteer\\autosteerfunctions.py:66\u001b[0m, in \u001b[0;36mcalculate_difference_line\u001b[1;34m(img, show, nbins)\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;66;03m#linear regression with sklearn\u001b[39;00m\n\u001b[0;32m     65\u001b[0m model \u001b[38;5;241m=\u001b[39m LinearRegression()\n\u001b[1;32m---> 66\u001b[0m pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_arr\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_arr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     67\u001b[0m x_1d \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m750\u001b[39m,\u001b[38;5;241m1000\u001b[39m) \u001b[38;5;66;03m#hier muss theoertisch nur in der Mitte des Bildes die Xwerte angeschaut werden\u001b[39;00m\n\u001b[0;32m     68\u001b[0m x \u001b[38;5;241m=\u001b[39m x_1d\u001b[38;5;241m.\u001b[39mreshape((\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_base.py:684\u001b[0m, in \u001b[0;36mLinearRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    680\u001b[0m n_jobs_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs\n\u001b[0;32m    682\u001b[0m accept_sparse \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpositive \u001b[38;5;28;01melse\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsc\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcoo\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m--> 684\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    685\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_numeric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmulti_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[0;32m    686\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    688\u001b[0m sample_weight \u001b[38;5;241m=\u001b[39m _check_sample_weight(\n\u001b[0;32m    689\u001b[0m     sample_weight, X, dtype\u001b[38;5;241m=\u001b[39mX\u001b[38;5;241m.\u001b[39mdtype, only_non_negative\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    690\u001b[0m )\n\u001b[0;32m    692\u001b[0m X, y, X_offset, y_offset, X_scale \u001b[38;5;241m=\u001b[39m _preprocess_data(\n\u001b[0;32m    693\u001b[0m     X,\n\u001b[0;32m    694\u001b[0m     y,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    698\u001b[0m     sample_weight\u001b[38;5;241m=\u001b[39msample_weight,\n\u001b[0;32m    699\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:596\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    594\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[0;32m    595\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 596\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m check_X_y(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[0;32m    597\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    599\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:1074\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1069\u001b[0m         estimator_name \u001b[38;5;241m=\u001b[39m _check_estimator_name(estimator)\n\u001b[0;32m   1070\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1071\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires y to be passed, but the target y is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1072\u001b[0m     )\n\u001b[1;32m-> 1074\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1075\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1076\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1077\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_large_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1078\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1079\u001b[0m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1080\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1081\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1082\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_2d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1083\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1084\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1085\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1086\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1087\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1088\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1090\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[0;32m   1092\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:909\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    907\u001b[0m     n_samples \u001b[38;5;241m=\u001b[39m _num_samples(array)\n\u001b[0;32m    908\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_samples \u001b[38;5;241m<\u001b[39m ensure_min_samples:\n\u001b[1;32m--> 909\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    910\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m sample(s) (shape=\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m) while a\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    911\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m minimum of \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m is required\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    912\u001b[0m             \u001b[38;5;241m%\u001b[39m (n_samples, array\u001b[38;5;241m.\u001b[39mshape, ensure_min_samples, context)\n\u001b[0;32m    913\u001b[0m         )\n\u001b[0;32m    915\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_min_features \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m array\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m    916\u001b[0m     n_features \u001b[38;5;241m=\u001b[39m array\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n",
      "\u001b[1;31mValueError\u001b[0m: Found array with 0 sample(s) (shape=(0, 1)) while a minimum of 1 is required by LinearRegression."
     ]
    }
   ],
   "source": [
    "#img = io.imread('./images/img5.jpg')\n",
    "from autosteerfunctions import calculate_difference_line\n",
    "from simple_pid import PID\n",
    "import cv2\n",
    "import numpy as np\n",
    "import win32gui\n",
    "from PIL import ImageGrab\n",
    "import time\n",
    "\n",
    "time.sleep(3)\n",
    "\n",
    "windows_list = []\n",
    "toplist = []\n",
    "def enum_win(hwnd, result):\n",
    "    win_text = win32gui.GetWindowText(hwnd)\n",
    "    windows_list.append((hwnd, win_text))\n",
    "win32gui.EnumWindows(enum_win, toplist)\n",
    "\n",
    "# Game handle\n",
    "game_hwnd = 0\n",
    "for (hwnd, win_text) in windows_list:\n",
    "    #print(hwnd)\n",
    "    print(win_text)\n",
    "    if win_text == \"Farming Simulator 22\":\n",
    "        print(\"found game\")\n",
    "        game_hwnd = hwnd\n",
    "        break\n",
    "        \n",
    "position = win32gui.GetWindowRect(game_hwnd)\n",
    "pid = PID(4, 0.1, 0.05, setpoint=120)\n",
    "while True:\n",
    "    screenshot = ImageGrab.grab(position)\n",
    "    screenshot = np.array(screenshot)\n",
    "    screenshot = cv2.cvtColor(screenshot, cv2.COLOR_RGB2BGR)\n",
    "    diff_line,image = calculate_difference_line(screenshot,False)\n",
    "    print(diff_line)\n",
    "\n",
    "\n",
    "#diff_line,image = calculate_difference_line(img,False)\n",
    "#if image is not None:\n",
    "#    plt.imshow(image)\n",
    "#print(diff_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e4377af-eaf1-48af-8bc0-160ca801f697",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
